{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext aymurai.devtools.magic\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from aymurai.spacy.display import DocRender\n",
    "from aymurai.pipeline import AymurAIPipeline\n",
    "from aymurai.datasets.ar_juz_pcyf_10 import ArgentinaJuzgadoPCyF10Dataset\n",
    "\n",
    "render = DocRender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "private = ArgentinaJuzgadoPCyF10Dataset('private', use_cache=True)\n",
    "train, test = train_test_split(private, test_size=0.2, random_state=22)\n",
    "train, val = train_test_split(train, test_size=0.2, random_state=22)\n",
    "print('train:', len(train))\n",
    "print('test:', len(test))\n",
    "print('val:', len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%export aymurai.spacy.rulers.section_parser\n",
    "from copy import deepcopy\n",
    "from functools import partial\n",
    "\n",
    "from spacy.tokens import Span\n",
    "from more_itertools import zip_offset\n",
    "\n",
    "import aymurai.spacy.components\n",
    "from aymurai.spacy.utils import load_base, format_entity\n",
    "from aymurai.spacy.components.regex import EnhancedRegexRuler\n",
    "from aymurai.meta.pipeline_interfaces import DataItem, DataBlock, Transform\n",
    "\n",
    "\n",
    "class AymuraiRulerSectionParser(Transform):\n",
    "    def __init__(\n",
    "        self,\n",
    "        base: str,\n",
    "        breakpoints: dict,\n",
    "        context_offset: int = 10,\n",
    "        spans_key: str = 'section'\n",
    "    ):\n",
    "        global __nlp\n",
    "        __nlp = load_base(base)\n",
    "        __nlp.add_pipe(\"enhanced_regex_ruler\", config={\"patterns\": breakpoints})\n",
    "\n",
    "        self.offset = context_offset\n",
    "\n",
    "        self.spans_key = spans_key\n",
    "\n",
    "    def __call__(self, item: DataItem) -> DataItem:\n",
    "        item = deepcopy(item)\n",
    "\n",
    "        doc = __nlp.pipe([item[\"data\"][\"doc.text\"]])\n",
    "        doc = list(doc)[0]\n",
    "\n",
    "        ents = sorted(doc.ents, key=lambda x: x.start_char)\n",
    "        if not ents:\n",
    "            return item\n",
    "        spans = [Span(doc, start=0, end=ents[0].start, label=\"SECTION:HEAD\")]\n",
    "\n",
    "        for ent1, ent2 in zip_offset(\n",
    "            ents,\n",
    "            ents,\n",
    "            offsets=(0, 1),\n",
    "            longest=True,\n",
    "            fillvalue=Span(doc, start=len(doc), end=len(doc)),\n",
    "        ):\n",
    "            spans.append(\n",
    "                Span(\n",
    "                    doc,\n",
    "                    start=ent1.start,\n",
    "                    end=ent2.start,\n",
    "                    label=ent1.label_,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        _format_entity = partial(format_entity, offset=self.offset)\n",
    "        formatted_ents = map(_format_entity, spans)\n",
    "\n",
    "        if not 'spans' in item['data']:\n",
    "            item['data']['spans'] = {}\n",
    "        if not self.spans_key in item['data']['spans']:\n",
    "            item['data']['spans'][self.spans_key] = []\n",
    "\n",
    "        item[\"data\"][\"spans\"][self.spans_key] += list(formatted_ents)\n",
    "\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aymurai.spacy.components\n",
    "from aymurai.text.normalize import TextNormalize\n",
    "from aymurai.spacy.ruler import SpacyRulerPipeline\n",
    "from aymurai.text.extraction import FulltextExtract\n",
    "from aymurai.spacy.rulers.section_parser import AymuraiRulerSectionParser\n",
    "\n",
    "config = {\n",
    "    \"preprocess\": [\n",
    "        (\n",
    "            FulltextExtract,\n",
    "            {\n",
    "                \"extension\": \"pdf\",\n",
    "                \"method\": \"tesseract\",\n",
    "                \"language\": \"spa\",\n",
    "                \"errors\": \"ignore\",\n",
    "                \"use_cache\": True,\n",
    "            },\n",
    "        ),\n",
    "        (TextNormalize, {}),\n",
    "        (\n",
    "            AymuraiRulerSectionParser,\n",
    "            {\n",
    "                \"base\": \"es\",\n",
    "                \"breakpoints\": {\n",
    "                    \"SECTION:DEVELOPMENT\": [\n",
    "                        \"DESARROLLO\",\n",
    "                    ],\n",
    "                    'SECTION:BACKGROUND': [\n",
    "                        \"ANTECEDENTES\",\n",
    "                        \"ANTECEDENTES Y ARGUMENTOS\",\n",
    "                    ],\n",
    "                    \"SECTION:ARGUMENTS\": [\n",
    "                        \"ARGUMENTOS\",\n",
    "                        \"ANTECEDENTES Y ARGUMENTOS\",\n",
    "                        'CONSIDERO'\n",
    "                    ],\n",
    "                    \"SECTION:DECISION\": [\n",
    "                        \"DECID[EO]\",\n",
    "                        \"RESUELV[EO]\",\n",
    "                    ],\n",
    "                    'KEYWORDS': [\n",
    "                        \"PALABRAS[_\\s]+CLAVE[\\w\\d\\s_:]+\",\n",
    "                    ]\n",
    "                },\n",
    "            },\n",
    "        ),\n",
    "    ],\n",
    "    \"models\": [],\n",
    "    \"postprocess\": [],\n",
    "    \"multiprocessing\": {},\n",
    "    \"use_cache\": False,\n",
    "    # 'log_level': 'debug'\n",
    "}\n",
    "\n",
    "pipeline = AymurAIPipeline(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = pipeline.preprocess(train)\n",
    "result = pipeline.predict(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "registry = result[1]\n",
    "metadata = {k: v for k, v in registry.items() if type(v) not in [dict, list]}\n",
    "print(json.dumps(metadata, indent=4))\n",
    "\n",
    "print('\\n-------\\n')\n",
    "render(registry, 'span', spans_key='section')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registry['data']['spans']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
