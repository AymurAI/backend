{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext aymurai.devtools.magic\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from aymurai.spacy.display import DocRender\n",
    "from aymurai.pipeline import AymurAIPipeline\n",
    "from aymurai.datasets.ar_juz_pcyf_10 import ArgentinaJuzgadoPCyF10Dataset\n",
    "\n",
    "colors = {\n",
    "    'SECTION:DECISION': 'red',\n",
    "    'KEYWORDS': 'blue'\n",
    "\n",
    "}\n",
    "render = DocRender(config={'colors': colors})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "private = ArgentinaJuzgadoPCyF10Dataset('private', use_cache=True)\n",
    "docs = ArgentinaJuzgadoPCyF10Dataset('private-docs', use_cache=True)\n",
    "docs = filter(lambda x: 'admisibilidad_prueba' not in x['metadata']['objeto_de_la_resolucion'], docs)\n",
    "docs = list(docs)\n",
    "\n",
    "train, test = train_test_split(private, test_size=0.2, random_state=22)\n",
    "train, val = train_test_split(train, test_size=0.2, random_state=22)\n",
    "print('train:', len(train))\n",
    "print('test:', len(test))\n",
    "print('val:', len(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pipeline definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%export aymurai.models.dummy.tipo_resolucion\n",
    "\n",
    "from copy import deepcopy\n",
    "from functools import reduce\n",
    "\n",
    "import regex\n",
    "\n",
    "from aymurai.utils.misc import get_element\n",
    "from aymurai.meta.types import DataItem, DataBlock\n",
    "from aymurai.meta.pipeline_interfaces import TrainModule\n",
    "\n",
    "\n",
    "class DummyExtractorTipoResolucion(TrainModule):\n",
    "    def save(self, path: str):\n",
    "        return\n",
    "\n",
    "    def load(self, path: str):\n",
    "        return\n",
    "\n",
    "    def fit(self, train: DataBlock, val: DataBlock):\n",
    "        return\n",
    "\n",
    "    def predict(self, data: DataBlock) -> DataBlock:\n",
    "        data = [self.predict_single(item) for item in data]\n",
    "\n",
    "        return data\n",
    "\n",
    "    def predict_single(self, item: DataItem) -> DataItem:\n",
    "        item = deepcopy(item)\n",
    "\n",
    "        # format prediction\n",
    "        if \"predictions\" not in item:\n",
    "            item[\"predictions\"] = {}\n",
    "        if \"records\" not in item[\"predictions\"]:\n",
    "            item[\"predictions\"][\"records\"] = {}\n",
    "        if \"entities\" not in item[\"predictions\"]:\n",
    "            item[\"predictions\"][\"entities\"] = []\n",
    "        if \"doc-cats\" not in item[\"predictions\"]:\n",
    "            item[\"predictions\"][\"doc-cats\"] = {}\n",
    "        item[\"predictions\"][\"doc-cats\"][\"tipo_de_resolucion\"] = \"interlocutoria\"\n",
    "        item[\"predictions\"][\"records\"][\"tipo_de_resolucion\"] = [\"interlocutoria\"]\n",
    "\n",
    "        # skip if there are no section parser\n",
    "        if not (sections := get_element(item, [\"data\", \"spans\", \"section\"], [])):\n",
    "            return item\n",
    "\n",
    "        sections = filter(\n",
    "            lambda x: x[\"label\"] in ['SECTION:HEAD', \"SECTION:DECISION\", \"KEYWORDS\"],\n",
    "            sections,\n",
    "        )\n",
    "        sections = sorted(sections, key=lambda e: e[\"start\"])\n",
    "\n",
    "        if not sections:\n",
    "            return item\n",
    "\n",
    "        text = reduce(lambda x, y: x + y, map(lambda z: z[\"text\"], sections))\n",
    "        # text = item['data']['doc.text']\n",
    "\n",
    "        patterns = [r\"(?i)interlocutoria\"]\n",
    "\n",
    "        interlocutoria = regex.findall(r\"(?i)interlocutoria{e<=2}\", text)\n",
    "        definitiva = regex.findall(r\"(?i)resoluci[oó]n[_\\s]+definitiva{e<=2}\", text)\n",
    "\n",
    "        tipo_resolucion = \"definitiva\" if definitiva else \"interlocutoria\"\n",
    "\n",
    "        item[\"predictions\"][\"records\"][\"tipo_de_resolucion\"].append(tipo_resolucion)\n",
    "        item[\"predictions\"][\"doc-cats\"][\"tipo_de_resolucion\"] = tipo_resolucion\n",
    "\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' Resumen : resolución definitiva que declara extinguida la sanción por prescripción ( art . 43 Código Contravencional , en adelante Co ) . Buenos Aires , M/ de agosto de 2018 . ANTECEDENTESSECTION:BACKGROUND ; El día 22 de octubre de '\n",
    "definitiva = regex.findall(r\"(?i)resoluci[oó]n[_\\s]+definitiva{e<=2}\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "definitiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aymurai.spacy.components\n",
    "from aymurai.text.normalize import TextNormalize\n",
    "from aymurai.spacy.ruler import SpacyRulerPipeline\n",
    "from aymurai.text.extraction import FulltextExtract\n",
    "from aymurai.spacy.rulers.section_parser import AymuraiRulerSectionParser\n",
    "from aymurai.models.dummy.tipo_resolucion import DummyExtractorTipoResolucion\n",
    "\n",
    "config = {\n",
    "    \"preprocess\": [\n",
    "        (\n",
    "            FulltextExtract,\n",
    "            {\n",
    "                \"extension\": \"pdf\",\n",
    "                \"method\": \"tesseract\",\n",
    "                \"language\": \"spa\",\n",
    "                \"errors\": \"ignore\",\n",
    "                \"use_cache\": True,\n",
    "            },\n",
    "        ),\n",
    "        (TextNormalize, {}),\n",
    "        (\n",
    "            AymuraiRulerSectionParser,\n",
    "            {\n",
    "                \"base\": \"es\",\n",
    "                \"breakpoints\": {\n",
    "                    \"SECTION:DEVELOPMENT\": [\n",
    "                        \"DESARROLLO\",\n",
    "                    ],\n",
    "                    'SECTION:BACKGROUND': [\n",
    "                        \"ANTECEDENTES\",\n",
    "                        \"ANTECEDENTES Y ARGUMENTOS\",\n",
    "                        \"Antecedentes del caso\"\n",
    "                    ],\n",
    "                    \"SECTION:ARGUMENTS\": [\n",
    "                        \"ARGUMENTOS\",\n",
    "                        \"ANTECEDENTES Y ARGUMENTOS\",\n",
    "                        'CONSIDERO'\n",
    "                    ],\n",
    "                    \"SECTION:DECISION\": [\n",
    "                        \"DECID[EO]\",\n",
    "                        \"RESUELV[EO]\",\n",
    "                    ],\n",
    "                    'KEYWORDS': [\n",
    "                        \"PALABRAS[_\\s]+CLAVES?[\\w\\d\\s_:]*\",\n",
    "                    ]\n",
    "                },\n",
    "            },\n",
    "        ),\n",
    "    ],\n",
    "    \"models\": [\n",
    "        (DummyExtractorTipoResolucion, {})\n",
    "    ],\n",
    "    \"postprocess\": [],\n",
    "    \"multiprocessing\": {},\n",
    "    \"use_cache\": False,\n",
    "    # 'log_level': 'debug'\n",
    "}\n",
    "\n",
    "pipeline = AymurAIPipeline(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = pipeline.preprocess(train)\n",
    "result = pipeline.predict(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "definitiva = filter(lambda x: any(map(lambda y: y['tipo_de_resolucion'] == 'definitiva', x['annotations'])), result)\n",
    "definitiva = list(definitiva)\n",
    "\n",
    "# registry = result[random.choice(range(len(result)))]\n",
    "registry = definitiva[3]\n",
    "metadata = {k: v for k, v in registry['metadata'].items() if type(v) not in [dict, list]}\n",
    "print(json.dumps(metadata, indent=4))\n",
    "\n",
    "annotations = registry['annotations']\n",
    "print('annotations')\n",
    "display(pd.DataFrame(annotations, index=pd.Index(range(len(annotations)))))\n",
    "\n",
    "print('predictions')\n",
    "if 'predictions' in registry:\n",
    "    pred_cats = {\n",
    "        k: v\n",
    "        for k, v in registry[\"predictions\"][\"doc-cats\"].items()\n",
    "        if type(v) not in [dict, list]\n",
    "    }\n",
    "    display(pd.DataFrame(pred_cats, index=pd.Index([0])).T)\n",
    "\n",
    "\n",
    "print('annotations')\n",
    "print('decision:', [x['tipo_de_resolucion'] for x in registry['annotations']])\n",
    "print('prediction')\n",
    "print(registry['predictions']['doc-cats'])\n",
    "print('decision:', registry['predictions']['doc-cats']['tipo_de_resolucion'])\n",
    "\n",
    "\n",
    "print('\\n-------\\n')\n",
    "# render(registry, 'span', spans_key='section')\n",
    "render(registry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = pipeline.preprocess(train)\n",
    "result = pipeline.predict(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from more_itertools import collapse\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from aymurai.meta.types import DataItem\n",
    "\n",
    "\n",
    "def annot_dataframe(item: DataItem) -> pd.DataFrame:\n",
    "    path = item['path']\n",
    "    annots = item['annotations']\n",
    "    df = pd.DataFrame(annots)\n",
    "    df.insert(0, 'path', path)\n",
    "\n",
    "    df = df[['path', 'tipo_de_resolucion']]\n",
    "    return df\n",
    "\n",
    "def preds_dataframe(item: DataItem) -> pd.DataFrame:\n",
    "    path = item['path']\n",
    "    preds = item['predictions']['doc-cats']\n",
    "    df = pd.DataFrame([preds])\n",
    "    df.insert(0, 'path', path)\n",
    "    return df\n",
    "\n",
    "references = pd.concat(map(annot_dataframe, result), ignore_index=True)\n",
    "references = references.rename(columns={'tipo_de_resolucion': 'reference'})\n",
    "\n",
    "hypotheses = pd.concat(map(preds_dataframe, result), ignore_index=True)\n",
    "hypotheses = hypotheses.rename(columns={'tipo_de_resolucion': 'hypothesis'})\n",
    "\n",
    "df = pd.merge(references, hypotheses, on='path')\n",
    "report = classification_report(df['reference'], df['hypothesis'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = pipeline.preprocess(test)\n",
    "result = pipeline.predict(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from more_itertools import collapse\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from aymurai.meta.types import DataItem\n",
    "\n",
    "\n",
    "def annot_dataframe(item: DataItem) -> pd.DataFrame:\n",
    "    path = item['path']\n",
    "    annots = item['annotations']\n",
    "    df = pd.DataFrame(annots)\n",
    "    df.insert(0, 'path', path)\n",
    "\n",
    "    df = df[['path', 'tipo_de_resolucion']]\n",
    "    return df\n",
    "\n",
    "def preds_dataframe(item: DataItem) -> pd.DataFrame:\n",
    "    path = item['path']\n",
    "    preds = item['predictions']['doc-cats']\n",
    "    df = pd.DataFrame([preds])\n",
    "    df.insert(0, 'path', path)\n",
    "    return df\n",
    "\n",
    "references = pd.concat(map(annot_dataframe, result), ignore_index=True)\n",
    "references = references.rename(columns={'tipo_de_resolucion': 'reference'})\n",
    "\n",
    "hypotheses = pd.concat(map(preds_dataframe, result), ignore_index=True)\n",
    "hypotheses = hypotheses.rename(columns={'tipo_de_resolucion': 'hypothesis'})\n",
    "\n",
    "df = pd.merge(references, hypotheses, on='path')\n",
    "df['exact_match'] = df['reference'] == df['hypothesis']\n",
    "\n",
    "report = classification_report(df['reference'], df['hypothesis'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = pipeline.preprocess(docs)\n",
    "result = pipeline.predict(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from more_itertools import collapse\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from aymurai.meta.types import DataItem\n",
    "\n",
    "\n",
    "def annot_dataframe(item: DataItem) -> pd.DataFrame:\n",
    "    path = item['path']\n",
    "    annots = item['annotations']\n",
    "    df = pd.DataFrame(annots)\n",
    "    df.insert(0, 'path', path)\n",
    "\n",
    "    df = df[['path', 'tipo_de_resolucion']]\n",
    "    return df\n",
    "\n",
    "def preds_dataframe(item: DataItem) -> pd.DataFrame:\n",
    "    path = item['path']\n",
    "    preds = item['predictions']['doc-cats']\n",
    "    df = pd.DataFrame([preds])\n",
    "    df.insert(0, 'path', path)\n",
    "    return df\n",
    "\n",
    "references = pd.concat(map(annot_dataframe, result), ignore_index=True)\n",
    "references = references.rename(columns={'tipo_de_resolucion': 'reference'})\n",
    "\n",
    "hypotheses = pd.concat(map(preds_dataframe, result), ignore_index=True)\n",
    "hypotheses = hypotheses.rename(columns={'tipo_de_resolucion': 'hypothesis'})\n",
    "\n",
    "df = pd.merge(references, hypotheses, on='path')\n",
    "df['exact_match'] = df['reference'] == df['hypothesis']\n",
    "\n",
    "report = classification_report(df['reference'], df['hypothesis'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
