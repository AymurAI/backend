{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow_hub tensorflow-gpu tensorflow_text tensorflow-addons tf-sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext aymurai.devtools.magic\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import locale\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from aymurai.spacy.display import DocRender\n",
    "from aymurai.pipeline import AymurAIPipeline\n",
    "from aymurai.datasets.ar_juz_pcyf_10 import ArgentinaJuzgadoPCyF10Dataset\n",
    "\n",
    "locale.setlocale(locale.LC_ALL, 'es_AR.UTF-8')\n",
    "render = DocRender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "private = ArgentinaJuzgadoPCyF10Dataset('private', use_cache=True)\n",
    "train, test = train_test_split(private, test_size=0.2, random_state=22)\n",
    "train, val = train_test_split(train, test_size=0.2, random_state=22)\n",
    "print('train:', len(train))\n",
    "print('test:', len(test))\n",
    "print('val:', len(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from aymurai.meta.types import DataItem\n",
    "from aymurai.meta.pipeline_interfaces import Transform\n",
    "\n",
    "\n",
    "class ViolenceDocCategoryParser(Transform):\n",
    "    categories = ['violencia_de_genero']\n",
    "    \n",
    "    def __call__(self, item: DataItem) -> DataItem:\n",
    "        item = deepcopy(item)\n",
    "        annotations = pd.DataFrame(item['annotations'])\n",
    "        annotations = annotations[self.categories].any().to_list()\n",
    "\n",
    "        item['data']['doc-cats'] = {\n",
    "            f'{cat}': int(value) for cat, value in zip(self.categories, annotations)\n",
    "        }\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aymurai.spacy.models.core import SpacyModel\n",
    "from aymurai.text.normalize import TextNormalize\n",
    "from aymurai.spacy.ruler import SpacyRulerPipeline\n",
    "from aymurai.text.extraction import FulltextExtract\n",
    "\n",
    "config = {\n",
    "    \"preprocess\": [\n",
    "        (\n",
    "            FulltextExtract,\n",
    "            {\n",
    "                \"extension\": \"pdf\",\n",
    "                \"method\": \"tesseract\",\n",
    "                \"language\": \"spa\",\n",
    "                \"errors\": \"ignore\",\n",
    "                \"use_cache\": True,\n",
    "            },\n",
    "        ),\n",
    "        (TextNormalize, {}),\n",
    "        (ViolenceDocCategoryParser, {}),\n",
    "    ],\n",
    "    \"models\": [\n",
    "    ],\n",
    "    \"postprocess\": [],\n",
    "    \"multiprocessing\": {},\n",
    "    \"use_cache\": False,\n",
    "    # 'log_level': 'debug'\n",
    "}\n",
    "\n",
    "pipeline = AymurAIPipeline(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train = pipeline.preprocess(train)\n",
    "preprocessed_val = pipeline.preprocess(val)\n",
    "preprocessed_test = pipeline.preprocess(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train = map(lambda x: x['data']['doc.text'], preprocessed_train)\n",
    "x_train = np.array(list(x_train))\n",
    "y_train = map(lambda x: x['data']['doc-cats']['violencia_de_genero'], preprocessed_train)\n",
    "y_train = np.array(list(y_train))\n",
    "\n",
    "x_val = map(lambda x: x['data']['doc.text'], preprocessed_val)\n",
    "x_val = np.array(list(x_val))\n",
    "y_val = map(lambda x: x['data']['doc-cats']['violencia_de_genero'], preprocessed_val)\n",
    "y_val = np.array(list(y_val))\n",
    "\n",
    "x_test = map(lambda x: x['data']['doc.text'], preprocessed_test)\n",
    "x_test = np.array(list(x_test))\n",
    "y_test = map(lambda x: x['data']['doc-cats']['violencia_de_genero'], preprocessed_test)\n",
    "y_test = np.array(list(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {1: y_train.sum()/len(y_train)}\n",
    "class_weights[0] = 1 - class_weights[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tqdm.auto import tqdm\n",
    "import tensorflow_text as text\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_addons as tfa\n",
    "from more_itertools import flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
    "\n",
    "f1_score = tfa.metrics.F1Score(num_classes=1, average=\"macro\", name=\"f1_score\")\n",
    "adamw = tf.keras.optimizers.experimental.AdamW()\n",
    "\n",
    "def get_model(encoder_trainable: bool = False) -> Model:\n",
    "\n",
    "    input_ = Input(shape=[], dtype=tf.string)\n",
    "    x = hub.KerasLayer(\n",
    "        # \"https://tfhub.dev/google/sentence-t5/st5-base/1\",\n",
    "        # \"https://tfhub.dev/google/universal-sentence-encoder-large/5\",\n",
    "        # \"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "        # \"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\",\n",
    "        \"https://tfhub.dev/google/nnlm-es-dim128/2\",\n",
    "        # \"https://tfhub.dev/google/universal-sentence-encoder-cmlm/multilingual-base/1\",\n",
    "        trainable=encoder_trainable,\n",
    "    )(input_)\n",
    "\n",
    "    embed_shape = x.shape[1]\n",
    "    x = Dense(embed_shape, activation=\"relu\")(x)\n",
    "    x = Dense(embed_shape, activation=\"relu\")(x)\n",
    "\n",
    "    output = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=[input_], outputs=output)\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        # optimizer=\"adam\",\n",
    "        optimizer=adamw,\n",
    "        metrics=[\"accuracy\", f1_score],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_model(encoder_trainable=True)\n",
    "model.summary()\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\"glove_embeddings_sequence_model.keras\", save_best_only=True),\n",
    "    EarlyStopping(patience=15, monitor=\"val_loss\", restore_best_weights=True),\n",
    "]\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=50,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weights,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## private"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, subplot = plt.subplots(2, 3, figsize=(20, 10))\n",
    "\n",
    "print(\"TRAIN\")\n",
    "hypothesis = model.predict(x_train)\n",
    "reference = y_train\n",
    "report = classification_report(reference, hypothesis > 0.5)\n",
    "confusion = confusion_matrix(reference, hypothesis > 0.5)\n",
    "sns.heatmap(confusion, ax=subplot[0, 0], annot=True, fmt=\"d\")\n",
    "subplot[1, 0].text(0, 0.5, report, fontfamily='monospace')\n",
    "# print(report)\n",
    "\n",
    "print(\"val\")\n",
    "hypothesis = model.predict(x_val)\n",
    "reference = y_val\n",
    "report = classification_report(reference, hypothesis > 0.5)\n",
    "confusion = confusion_matrix(reference, hypothesis > 0.5)\n",
    "sns.heatmap(confusion, ax=subplot[0, 1], annot=True, fmt=\"d\")\n",
    "subplot[1, 1].text(0, 0.5, report, fontfamily='monospace')\n",
    "# print(report)\n",
    "\n",
    "print(\"TEST\")\n",
    "hypothesis = model.predict(x_test)\n",
    "reference = y_test\n",
    "report = classification_report(reference, hypothesis > 0.5)\n",
    "confusion = confusion_matrix(reference, hypothesis > 0.5)\n",
    "sns.heatmap(confusion, ax=subplot[0, 2], annot=True, fmt=\"d\")\n",
    "subplot[1, 2].text(0, 0.5, report, fontfamily='monospace')\n",
    "# print(report)\n",
    "\n",
    "subplot[0, 0].set_title(\"TRAIN\")\n",
    "subplot[0, 1].set_title(\"VALIDATION\")\n",
    "subplot[0, 2].set_title(\"TEST\")\n",
    "for ax in subplot[0]:\n",
    "    ax.set_xlabel(\"hypothesis\")\n",
    "    ax.set_ylabel(\"reference\")\n",
    "    ax.set_xticklabels([\"false\", \"true\"])\n",
    "    ax.set_yticklabels([\"false\", \"true\"])\n",
    "\n",
    "for ax in subplot[1]:\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## public"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public = ArgentinaJuzgadoPCyF10Dataset('latest', use_cache=True)\n",
    "preprocessed = pipeline.preprocess(public)\n",
    "\n",
    "x_train = map(lambda x: x['data']['doc.text'], preprocessed)\n",
    "x_train = np.array(list(x_train))\n",
    "y_train = map(lambda x: x['data']['doc-cats']['violencia_de_genero'], preprocessed)\n",
    "y_train = np.array(list(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, subplot = plt.subplots(2, 3, figsize=(20, 10))\n",
    "\n",
    "print(\"PUBLIC\")\n",
    "hypothesis = model.predict(x_train)\n",
    "reference = y_train\n",
    "report = classification_report(reference, hypothesis > 0.5)\n",
    "confusion = confusion_matrix(reference, hypothesis > 0.5)\n",
    "sns.heatmap(confusion, ax=subplot[0, 0], annot=True, fmt=\"d\")\n",
    "subplot[1, 0].text(0, 0.5, report, fontfamily='monospace')\n",
    "# print(report)\n",
    "\n",
    "\n",
    "subplot[0, 0].set_title(\"PUBLIC\")\n",
    "for ax in subplot[0]:\n",
    "    ax.set_xlabel(\"hypothesis\")\n",
    "    ax.set_ylabel(\"reference\")\n",
    "    ax.set_xticklabels([\"false\", \"true\"])\n",
    "    ax.set_yticklabels([\"false\", \"true\"])\n",
    "\n",
    "for ax in subplot[1]:\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/resources/checkpoints/usem-gender-violence-binary-cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('/resources/checkpoints/usem-gender-violence-binary-cat')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
