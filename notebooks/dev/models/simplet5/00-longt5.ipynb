{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install  transformers==4.20.1\n",
    "!pip install --no-deps git+https://github.com/Shivanandroy/simpleT5.git@4c1afee10bf822ab711660cf7fe20595f1f368e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze | grep -e transformers -e simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext aymurai.devtools\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import locale\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from aymurai.spacy.display import DocRender\n",
    "from aymurai.pipeline import AymurAIPipeline\n",
    "from aymurai.datasets.ar_juz_pcyf_10 import ArgentinaJuzgadoPCyF10Dataset\n",
    "\n",
    "locale.setlocale(locale.LC_ALL, 'es_AR.UTF-8')\n",
    "render = DocRender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "private = ArgentinaJuzgadoPCyF10Dataset('private', use_cache=True)\n",
    "train, test = train_test_split(private, test_size=0.2, random_state=22)\n",
    "train, val = train_test_split(train, test_size=0.2, random_state=22)\n",
    "print('train:', len(train))\n",
    "print('test:', len(test))\n",
    "print('val:', len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aymurai.spacy.components\n",
    "from aymurai.spacy.models.core import SpacyModel\n",
    "from aymurai.text.normalize import TextNormalize\n",
    "from aymurai.spacy.ruler import SpacyRulerPipeline\n",
    "from aymurai.text.extraction import FulltextExtract\n",
    "\n",
    "config = {\n",
    "    \"preprocess\": [\n",
    "        (\n",
    "            FulltextExtract,\n",
    "            {\n",
    "                \"extension\": \"pdf\",\n",
    "                \"method\": \"tesseract\",\n",
    "                \"language\": \"spa\",\n",
    "                \"errors\": \"ignore\",\n",
    "                \"use_cache\": True,\n",
    "            },\n",
    "        ),\n",
    "        (TextNormalize, {}),\n",
    "        (\n",
    "            SpacyRulerPipeline,\n",
    "            {\n",
    "                \"base\": \"es\",\n",
    "                \"steps\": [(\"aymurai_violence_quotes_ruler\", {})],\n",
    "            },\n",
    "        ),\n",
    "    ],\n",
    "    \"models\": [],\n",
    "    \"postprocess\": [],\n",
    "    \"multiprocessing\": {},\n",
    "    \"use_cache\": True,\n",
    "    # 'log_level': 'debug'\n",
    "}\n",
    "\n",
    "pipeline = AymurAIPipeline(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed = pipeline.preprocess(private)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def have_quotes_entities(item)-> bool:\n",
    "    if 'data' not in item:\n",
    "        return False\n",
    "    if 'entities' not in item['data']:\n",
    "        return False\n",
    "    \n",
    "    if not item['metadata']['frases_agresion']:\n",
    "        return False\n",
    "    \n",
    "    labels = list(map(lambda x: x['label'], item['data']['entities']))\n",
    "    return 'AYMURAI_VIOLENCE_QUOTE' in labels\n",
    "    \n",
    "with_quotes = filter(have_quotes_entities, preprocessed)\n",
    "with_quotes = list(with_quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(with_quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from more_itertools import unique_everseen\n",
    "\n",
    "texts = map(lambda x: x[\"data\"][\"doc.text\"], with_quotes)\n",
    "texts = list(texts)\n",
    "\n",
    "quotes = map(\n",
    "    lambda x: list(\n",
    "        unique_everseen(\n",
    "            filter(bool, map(lambda y: y[\"frases_agresion\"], x[\"annotations\"]))\n",
    "        )\n",
    "    ),\n",
    "    with_quotes,\n",
    ")\n",
    "quotes = map(lambda x: ', '.join(x), quotes)\n",
    "quotes = list(quotes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'source_text': [f'question: cuales son las frases de violencia? context: {text} </s>' for text in texts],\n",
    "    'target_text': [f'{target} </s>' for target in quotes]\n",
    "})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simplet5 import SimpleT5\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# instantiate\n",
    "model = SimpleT5()\n",
    "\n",
    "# load (supports t5, mt5, byT5 models)\n",
    "model.from_pretrained(\"longt5\",\"google/long-t5-local-base\")\n",
    "# model.tokenizer = AutoTokenizer.from_pretrained(\"google/long-t5-local-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = (model.tokenizer(doc)['input_ids'] for doc in data['source_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "lens = np.array([len(token) for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.distplot(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=22)\n",
    "train, val = train_test_split(train, test_size=0.2, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(\n",
    "    train_df=train,  # pandas dataframe with 2 columns: source_text & target_text\n",
    "    eval_df=val,  # pandas dataframe with 2 columns: source_text & target_text\n",
    "    source_max_token_len=20480,\n",
    "    target_max_token_len=128,\n",
    "    batch_size=1,\n",
    "    max_epochs=5,\n",
    "    use_gpu=True,\n",
    "    outputdir=\"outputs\",\n",
    "    early_stopping_patience_epochs=0,\n",
    "    precision=32,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
