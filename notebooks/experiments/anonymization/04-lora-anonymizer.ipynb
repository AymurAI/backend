{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo pip install transformers peft evaluate seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "ANNOT_DIR = \"/resources/data/restricted/anonymization\"\n",
    "\n",
    "train = pd.read_csv(\n",
    "    f\"{ANNOT_DIR}/train.txt\",\n",
    "    sep=\" \",\n",
    "    names=[\"token\", \"label\"],\n",
    "    skip_blank_lines=False,\n",
    ")\n",
    "\n",
    "val = pd.read_csv(\n",
    "    f\"{ANNOT_DIR}/dev.txt\",\n",
    "    sep=\" \",\n",
    "    names=[\"token\", \"label\"],\n",
    "    skip_blank_lines=False,\n",
    ")\n",
    "\n",
    "test = pd.read_csv(\n",
    "    f\"{ANNOT_DIR}/test.txt\",\n",
    "    sep=\" \",\n",
    "    names=[\"token\", \"label\"],\n",
    "    skip_blank_lines=False,\n",
    ")\n",
    "\n",
    "\n",
    "cat_count = dict(train[\"label\"].value_counts())\n",
    "categories = {v: k for k, v in enumerate(train[\"label\"].unique()) if not pd.isna(v)}\n",
    "label2code = {k: i for i, (k, v) in enumerate(categories.items())}\n",
    "code2label = {v: k for k, v in label2code.items()}\n",
    "\n",
    "print(\"train:\", len(train))\n",
    "print(\"val:\", len(val))\n",
    "print(\"test:\", len(test))\n",
    "print(\"nlabels:\", len(code2label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from more_itertools import unzip\n",
    "from tqdm.auto import tqdm\n",
    "from more_itertools import split_at\n",
    "\n",
    "\n",
    "def get_hg_format(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    df[\"tags\"] = df[\"label\"].map(lambda x: label2code.get(x, label2code[\"O\"]))\n",
    "    items = []\n",
    "    indices, rows = unzip(df.iterrows())\n",
    "    tuples = map(lambda row: (row[\"token\"], row[\"tags\"]), rows)\n",
    "    tuples = split_at(tuples, lambda x: pd.isna(x[0]))\n",
    "\n",
    "    for i, paragraph in enumerate(tuples):\n",
    "        df = pd.DataFrame(paragraph)\n",
    "        # if not 3 <= len(df) <= 10:\n",
    "        #     continue\n",
    "        if not len(df):\n",
    "            continue\n",
    "        tokens = df[0].values\n",
    "        labels = df[1].values.astype(int)\n",
    "        nlabels = (len(labels[labels > 0]),)\n",
    "\n",
    "        if any(np.isnan(labels)):\n",
    "            continue\n",
    "\n",
    "        # if nlabels == 0 and np.random.rand() < 0.99:\n",
    "        # print('skipping no entity paragraph')\n",
    "        # continue\n",
    "\n",
    "        if len(tokens) != len(labels):\n",
    "            print(\"mismatch size\")\n",
    "            continue\n",
    "\n",
    "        items.append(\n",
    "            {\n",
    "                \"n_labels\": nlabels,\n",
    "                \"tokens\": list(tokens),\n",
    "                \"tags\": labels,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd = get_hg_format(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(asd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict, Dataset\n",
    "\n",
    "dataset = DatasetDict(\n",
    "    {\n",
    "        \"train\": Dataset.from_list(get_hg_format(train)),\n",
    "        \"validation\": Dataset.from_list(get_hg_format(val)),\n",
    "        \"test\": Dataset.from_list(get_hg_format(test)),\n",
    "    }\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    TaskType,\n",
    ")\n",
    "import evaluate\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# model_checkpoint = \"roberta-large\"\n",
    "model_checkpoint = \"dccuchile/bert-base-spanish-wwm-cased\"\n",
    "lr = 1e-3\n",
    "batch_size = 8\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqeval = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokenized_dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(label2code), len(code2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels=len(label2code.keys()),\n",
    "    id2label=code2label,\n",
    "    label2id=label2code,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.TOKEN_CLS,\n",
    "    inference_mode=False,\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"all\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"beto-lora-aymurai-ner\",\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    # predict_with_generate=True,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=100,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = tokenized_dataset[\"validation\"].select(range(1000))\n",
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seqeval\n",
    "\n",
    "seqeval = evaluate.load(\"seqeval\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    predictions, labels = eval_preds\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [code2label.get(p) for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [code2label.get(l, \"O\") for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"].select(range(600)),\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(tokenized_dataset[\"validation\"].select(range(1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"./beto-lora-aymurai-ner/model/\"\n",
    "\n",
    "trainer.model.save_pretrained()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftConfig, PeftModelForTokenClassification, LoraConfig, TaskType, get_peft_model\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "\n",
    "MODEL_PATH = \"./beto-lora-aymurai-ner/model\"\n",
    "\n",
    "# Load peft config for pre-trained checkpoint etc.\n",
    "peft_config = PeftConfig.from_pretrained(MODEL_PATH)\n",
    "lora_config = LoraConfig(\n",
    "    base_model_name_or_path=model_checkpoint,\n",
    "    task_type=TaskType.TOKEN_CLS,\n",
    "    inference_mode=True,\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"all\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load base LLM model and tokenizer\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    peft_config.base_model_name_or_path,\n",
    "    num_labels=len(label2code.keys()),\n",
    "    id2label=code2label,\n",
    "    label2id=label2code,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(peft_config.base_model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = PeftModelForTokenClassification(model, peft_config)\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"El imputado Ramiro Ramallo Martinez dni 88.384.425\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "model.to(\"cpu\")\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "tokens = inputs.tokens()\n",
    "\n",
    "predictions = torch.argmax(logits, dim=2)\n",
    "\n",
    "for token, prediction in zip(tokens, predictions[0].numpy()):\n",
    "    print((token, model.config.id2label[prediction]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(tokenized_dataset[\"test\"].select(range(1000)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
