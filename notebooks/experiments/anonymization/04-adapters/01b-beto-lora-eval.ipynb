{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import srsly\n",
    "from huggingface_hub import hf_hub_download\n",
    "from peft import AutoPeftModelForTokenClassification\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "MODEL_NAME = \"aymurai/anonymizer-beto-cased-lora\"\n",
    "\n",
    "LABEL2CODE_PATH = hf_hub_download(repo_id=MODEL_NAME, filename=\"label2code.json\")\n",
    "\n",
    "with open(LABEL2CODE_PATH) as file:\n",
    "    label2code = srsly.json_loads(file.read())\n",
    "    code2label = {v: k for k, v in label2code.items()}\n",
    "\n",
    "model = AutoPeftModelForTokenClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(label2code.keys()),\n",
    "    id2label=code2label,\n",
    "    label2id=label2code,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model.peft_config[\"default\"].base_model_name_or_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from itertools import groupby\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from more_itertools import unzip\n",
    "\n",
    "from aymurai.logging import get_logger\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "\n",
    "def postprocessor(\n",
    "    token_ids: list[int], scores: list[float], aggregator: str = \"first\"\n",
    ") -> tuple[str, float]:\n",
    "    text = tokenizer.convert_tokens_to_string(token_ids)\n",
    "    text = re.sub(\"\\s+\", \"\", text)\n",
    "\n",
    "    # use the label of the top class of subwords\n",
    "    if aggregator == \"max\":\n",
    "        score = np.max(scores)\n",
    "        label_id = np.argmax(scores)\n",
    "    elif aggregator == \"first\":\n",
    "        score = np.max(scores[0])\n",
    "        label_id = np.argmax(scores[0])\n",
    "    else:\n",
    "        raise NotImplemented(f\"aggregation: `{aggregator}` not implemented.\")\n",
    "    # if label_id not in code2label:\n",
    "    #     logger.warn(f\"out of range class: `{text}` (label_id {label_id})\")\n",
    "    label = code2label.get(label_id, \"O\")\n",
    "\n",
    "    return text, label, score\n",
    "\n",
    "\n",
    "def single_predict(text: str, aggregator: str = \"first\"):\n",
    "    # print(text)\n",
    "    inputs = tokenizer(\n",
    "        text.split(), return_tensors=\"pt\", is_split_into_words=True, truncation=True\n",
    "    )\n",
    "    word_ids = inputs.word_ids()\n",
    "    tokens = inputs.tokens()\n",
    "    # model.to(\"cpu\")\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits.numpy()\n",
    "\n",
    "    maxes = np.max(logits, axis=-1, keepdims=True)\n",
    "    shifted_exp = np.exp(logits - maxes)\n",
    "    scores = shifted_exp / shifted_exp.sum(axis=-1, keepdims=True)\n",
    "\n",
    "    preds = groupby(zip(word_ids, tokens, scores[0]), key=lambda x: x[0])\n",
    "    preds = filter(lambda x: x[0] is not None, preds)  # drop non words tokens i.e [CLS]\n",
    "    _, preds = unzip(preds)  # drop group key (word id)\n",
    "    preds = map(lambda x: list(zip(*x)), preds)  # transpose list\n",
    "\n",
    "    # x = (word_id, token_ids, scores)\n",
    "    preds = map(lambda x: postprocessor(x[1], x[2], aggregator=aggregator), preds)\n",
    "\n",
    "    return list(preds)\n",
    "\n",
    "\n",
    "text = \"El imputado Ramiro Ramallo Martinez DNI 88.384.425 declarado\"\n",
    "single_predict(text, aggregator=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "DATASET_NAME = (\n",
    "    \"/resources/data/restricted/anonymization/annonimization-dataset-pruned-2023-08-16\"\n",
    ")\n",
    "dataset = load_from_disk(DATASET_NAME)\n",
    "\n",
    "dataset[\"train\"] = dataset[\"train\"].shuffle(seed=42)\n",
    "print(dataset)\n",
    "print(\"nlabels:\", len(code2label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dev evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "logger.setLevel(\"ERROR\")\n",
    "# train evaluation file\n",
    "predictions = pd.DataFrame()\n",
    "for paragraph in tqdm(dataset[\"validation\"]):\n",
    "    text = \" \".join(paragraph[\"tokens\"])\n",
    "    preds = single_predict(text, aggregator=\"first\")\n",
    "\n",
    "    preds = pd.DataFrame(preds, columns=[\"token\", \"pred\", \"score\"])\n",
    "    preds.insert(loc=1, column=\"label\", value=paragraph[\"tags\"])\n",
    "    preds[\"label\"] = preds[\"label\"].apply(code2label.get)\n",
    "    preds.loc[-1] = np.nan\n",
    "\n",
    "    predictions = pd.concat([predictions, preds], ignore_index=True)\n",
    "\n",
    "predictions.to_csv(\"dev-evaluation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- [ ] manejar parrafos con mas de 512 tokens (en training se trunco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = predictions.copy()\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exact match\n",
    "df[\"match\"] = df[\"label\"] == df[\"pred\"]\n",
    "df[\"match\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"label\"] != \"O\", \"match\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"label\"] == \"O\", \"match\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df[\"label\"] == \"O\") & (df[\"match\"] != 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_class = lambda x: re.sub(r\"B-|I-\", \"\", x)\n",
    "\n",
    "df[\"normalized_label\"] = df[\"label\"].map(normalize_class)\n",
    "df[\"normalized_pred\"] = df[\"pred\"].map(normalize_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized exact match\n",
    "df[\"normalized_match\"] = df[\"normalized_label\"] == df[\"normalized_pred\"]\n",
    "df[\"normalized_match\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"normalized_label\"] != \"O\", \"normalized_match\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"normalized_label\"] == \"O\", \"normalized_match\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"normalized_pred\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(df[\"label\"], df[\"pred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(df[\"normalized_label\"], df[\"normalized_pred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "labels = df[\"normalized_label\"].unique()\n",
    "\n",
    "cm = confusion_matrix(\n",
    "    df[\"normalized_label\"],\n",
    "    df[\"normalized_pred\"],\n",
    "    labels=labels,\n",
    "    # normalize=\"true\",\n",
    ")\n",
    "order = np.argsort(-cm.diagonal())\n",
    "\n",
    "\n",
    "cm_norm = confusion_matrix(\n",
    "    df[\"normalized_label\"],\n",
    "    df[\"normalized_pred\"],\n",
    "    labels=labels,\n",
    "    normalize=\"true\",\n",
    ")\n",
    "cm_sorted = cm_norm[order, :][:, order]\n",
    "\n",
    "labels_sorted = labels[order]\n",
    "\n",
    "sns.heatmap(\n",
    "    cm_sorted,\n",
    "    vmin=0.0,\n",
    "    vmax=1.0,\n",
    "    cmap=\"Blues\",\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cbar=False,\n",
    "    xticklabels=labels_sorted,\n",
    "    yticklabels=labels_sorted,\n",
    ")\n",
    "\n",
    "plt.title(\"Confusion Matrix\", fontdict={\"fontsize\": 20})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
