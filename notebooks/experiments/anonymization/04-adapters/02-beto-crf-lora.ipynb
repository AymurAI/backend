{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo pip install transformers peft evaluate seqeval\n",
    "!sudo pip install pytorch-crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "import srsly\n",
    "\n",
    "DATASET_NAME = (\n",
    "    \"/resources/data/restricted/anonymization/annonimization-dataset-pruned-2023-08-16\"\n",
    ")\n",
    "dataset = load_from_disk(DATASET_NAME)\n",
    "\n",
    "with open(f\"{DATASET_NAME}/label_mapping.json\") as file:\n",
    "    label2code = srsly.json_loads(file.read())\n",
    "    code2label = {v: k for k, v in label2code.items()}\n",
    "\n",
    "dataset[\"train\"] = dataset[\"train\"].shuffle(seed=42)\n",
    "print(dataset)\n",
    "print(\"nlabels:\", len(code2label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForTokenClassification,\n",
    ")\n",
    "import evaluate\n",
    "\n",
    "# model_checkpoint = \"roberta-large\"\n",
    "model_checkpoint = \"dccuchile/bert-base-spanish-wwm-cased\"\n",
    "# model_checkpoint = \"PlanTL-GOB-ES/RoBERTalex\"\n",
    "\n",
    "seqeval = evaluate.load(\"seqeval\")\n",
    "\n",
    "backbone = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels=len(label2code.keys()),\n",
    "    id2label=code2label,\n",
    "    label2id=label2code,\n",
    "    # device_map={0: \"cpu\"},\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokenized_dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchcrf import CRF\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "\n",
    "\n",
    "class TransformerCRF(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: AutoModelForTokenClassification,\n",
    "        num_labels: int,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.backbone = model\n",
    "        self.num_labels = num_labels\n",
    "        self.special_token = -100\n",
    "        self.crf = CRF(self.num_labels, batch_first=True)\n",
    "        self.config = self.backbone.config\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=True,\n",
    "    ):\n",
    "        return_dict = (\n",
    "            return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        )\n",
    "\n",
    "        outputs = self.backbone(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        # sequence_output = outputs.last_hidden_state\n",
    "        # sequence_output = self.dropout(output)\n",
    "        # logits = self.classifier(sequence_output)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            _labels = labels[:]\n",
    "            _labels[_labels == self.special_token] = 0\n",
    "\n",
    "            log_likelihood = self.crf(logits, _labels)\n",
    "            loss = 0 - log_likelihood\n",
    "\n",
    "            # tags = self.crf.decode(logits)\n",
    "\n",
    "        # tags = torch.Tensor(tags)\n",
    "\n",
    "        # output = (tags,) + outputs[2:]\n",
    "        # return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return TokenClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crfmodel = TransformerCRF(backbone, num_labels=len(code2label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"El imputado Ramiro Ramallo Martinez DNI 88.384.425 declarado\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "import torch\n",
    "\n",
    "\n",
    "example = tokenized_dataset[\"train\"][0]\n",
    "tags = example[\"tags\"]\n",
    "example[\"input_ids\"] = torch.tensor([example[\"input_ids\"]])\n",
    "example[\"token_type_ids\"] = torch.tensor([example[\"token_type_ids\"]])\n",
    "example[\"attention_mask\"] = torch.tensor([example[\"attention_mask\"]])\n",
    "example[\"labels\"] = torch.tensor([example[\"labels\"]])\n",
    "example.pop(\"n_labels\")\n",
    "example.pop(\"tokens\")\n",
    "example.pop(\"tags\")\n",
    "example.pop(\"hash\")\n",
    "# crfmodel.to(\"cpu\")\n",
    "\n",
    "# inputs = torch.tensor(example[\"input_ids\"])\n",
    "with torch.no_grad():\n",
    "    logits = backbone(**example)\n",
    "    logits = crfmodel(**example)\n",
    "logits\n",
    "# inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import TaskType, get_peft_model, LoraConfig\n",
    "\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.TOKEN_CLS,\n",
    "    inference_mode=False,\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_peft_model(crfmodel, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "seqeval = evaluate.load(\"seqeval\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    predictions, labels = eval_preds\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [code2label.get(p) for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [code2label.get(l, \"O\") for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "MODEL_NAME = \"beto-crf-lora-aymurai-ner\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=MODEL_NAME,\n",
    "    learning_rate=1e-3,\n",
    "    per_device_train_batch_size=12,\n",
    "    per_device_eval_batch_size=16,\n",
    "    # predict_with_generate=True,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=500,\n",
    "    save_steps=500,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "MODEL_PATH = f\"/resources/models/anonymization/{MODEL_NAME}\"\n",
    "\n",
    "os.makedirs(f\"{MODEL_PATH}/config\", exist_ok=True)\n",
    "with open(f\"{MODEL_PATH}/config/label_mapping.json\", \"w\") as file:\n",
    "    json = srsly.json_dumps(label2code)\n",
    "    file.write(json)\n",
    "\n",
    "model.save_pretrained(f\"{MODEL_PATH}/lora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import (\n",
    "    PeftConfig,\n",
    "    PeftModelForTokenClassification,\n",
    "    LoraConfig,\n",
    "    TaskType,\n",
    "    get_peft_model,\n",
    "    PeftModel,\n",
    ")\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "\n",
    "MODEL_PATH = \"./beto-lora-aymurai-ner/model\"\n",
    "\n",
    "# Load peft config for pre-trained checkpoint etc.\n",
    "peft_config = PeftConfig.from_pretrained(MODEL_PATH)\n",
    "\n",
    "# load base model and tokenizer\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    peft_config.base_model_name_or_path,\n",
    "    num_labels=len(label2code.keys()),\n",
    "    id2label=code2label,\n",
    "    label2id=label2code,\n",
    ")\n",
    "\n",
    "model = PeftModelForTokenClassification.from_pretrained(model, MODEL_PATH)\n",
    "model.eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_config.base_model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "text = \"El imputado Ramiro Ramallo Martinez DNI 88.384.425 declarado\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "model.to(\"cpu\")\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "tokens = inputs.tokens()\n",
    "\n",
    "predictions = torch.argmax(logits, dim=2)\n",
    "\n",
    "for token, prediction in zip(tokens, predictions[0].numpy()):\n",
    "    print((token, model.config.id2label[prediction]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from itertools import groupby\n",
    "\n",
    "import numpy as np\n",
    "from more_itertools import unzip, collapse\n",
    "from aymurai.logging import get_logger\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "\n",
    "def postprocessor(\n",
    "    token_ids: list[int], scores: list[float], aggregator: str = \"max\"\n",
    ") -> tuple[str, float]:\n",
    "    text = tokenizer.convert_tokens_to_string(token_ids)\n",
    "    text = re.sub(\"\\s+\", \"\", text)\n",
    "\n",
    "    # use the label of the top class of subwords\n",
    "    if aggregator == \"max\":\n",
    "        score = np.max(scores)\n",
    "        label_id = np.argmax(scores)\n",
    "    elif aggregator == \"first\":\n",
    "        score = np.max(scores[0])\n",
    "        label_id = np.argmax(scores[0])\n",
    "    else:\n",
    "        raise NotImplemented(f\"aggregation: `{aggregator}` not implemented.\")\n",
    "    # if label_id not in code2label:\n",
    "    #     logger.warn(f\"out of range class: `{text}` (label_id {label_id})\")\n",
    "    label = code2label.get(label_id, \"O\")\n",
    "\n",
    "    return text, label, score\n",
    "\n",
    "\n",
    "def single_predict(text: str, aggregator: str = \"max\"):\n",
    "    # print(text)\n",
    "    inputs = tokenizer(\n",
    "        text.split(), return_tensors=\"pt\", is_split_into_words=True, truncation=True\n",
    "    )\n",
    "    word_ids = inputs.word_ids()\n",
    "    tokens = inputs.tokens()\n",
    "    # model.to(\"cpu\")\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "\n",
    "    maxes = np.max(logits.numpy(), axis=-1, keepdims=True)\n",
    "    maxes = model.crf.decode(logits)\n",
    "    print(maxes)\n",
    "    shifted_exp = np.exp(logits - maxes)\n",
    "    scores = shifted_exp / shifted_exp.sum(axis=-1, keepdims=True)\n",
    "\n",
    "    preds = groupby(zip(word_ids, tokens, scores[0]), key=lambda x: x[0])\n",
    "    preds = filter(lambda x: x[0] is not None, preds)  # drop non words tokens i.e [CLS]\n",
    "    _, preds = unzip(preds)  # drop group key (word id)\n",
    "    preds = map(lambda x: list(zip(*x)), preds)  # transpose list\n",
    "\n",
    "    # x = (word_id, token_ids, scores)\n",
    "    preds = map(lambda x: postprocessor(x[1], x[2], aggregator=aggregator), preds)\n",
    "\n",
    "    return list(preds)\n",
    "\n",
    "\n",
    "single_predict(text, aggregator=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_predict(text, aggregator=\"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "import srsly\n",
    "\n",
    "DATASET_NAME = (\n",
    "    \"/resources/data/restricted/anonymization/annonimization-dataset-pruned-2023-08-16\"\n",
    ")\n",
    "dataset = load_from_disk(DATASET_NAME)\n",
    "\n",
    "with open(f\"{DATASET_NAME}/label_mapping.json\") as file:\n",
    "    label2code = srsly.json_loads(file.read())\n",
    "    code2label = {v: k for k, v in label2code.items()}\n",
    "\n",
    "dataset[\"train\"] = dataset[\"train\"].shuffle(seed=42)\n",
    "print(dataset)\n",
    "print(\"nlabels:\", len(code2label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dev evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "logger.setLevel(\"ERROR\")\n",
    "# train evaluation file\n",
    "predictions = pd.DataFrame()\n",
    "for paragraph in tqdm(dataset[\"validation\"]):\n",
    "    text = \" \".join(paragraph[\"tokens\"])\n",
    "    preds = single_predict(text, aggregator=\"first\")\n",
    "\n",
    "    preds = pd.DataFrame(preds, columns=[\"token\", \"pred\", \"score\"])\n",
    "    preds.insert(loc=1, column=\"label\", value=paragraph[\"tags\"])\n",
    "    preds[\"label\"] = preds[\"label\"].apply(code2label.get)\n",
    "    preds.loc[-1] = np.nan\n",
    "\n",
    "    predictions = pd.concat([predictions, preds], ignore_index=True)\n",
    "\n",
    "predictions.to_csv(\"dev-evaluation-beto-crf.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- [ ] manejar parrafos con mas de 512 tokens (en training se trunco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = predictions.copy()\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exact match\n",
    "df[\"match\"] = df[\"label\"] == df[\"pred\"]\n",
    "df[\"match\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"label\"] != \"O\", \"match\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"label\"] == \"O\", \"match\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df[\"label\"] == \"O\") & (df[\"match\"] != 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_class = lambda x: re.sub(r\"B-|I-\", \"\", x)\n",
    "\n",
    "df[\"normalized_label\"] = df[\"label\"].map(normalize_class)\n",
    "df[\"normalized_pred\"] = df[\"pred\"].map(normalize_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized exact match\n",
    "df[\"normalized_match\"] = df[\"normalized_label\"] == df[\"normalized_pred\"]\n",
    "df[\"normalized_match\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"normalized_label\"] != \"O\", \"normalized_match\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"normalized_label\"] == \"O\", \"normalized_match\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"normalized_pred\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(df[\"label\"], df[\"pred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(df[\"normalized_label\"], df[\"normalized_pred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "labels = df[\"normalized_label\"].unique()\n",
    "\n",
    "cm = confusion_matrix(\n",
    "    df[\"normalized_label\"],\n",
    "    df[\"normalized_pred\"],\n",
    "    labels=labels,\n",
    "    # normalize=\"true\",\n",
    ")\n",
    "order = np.argsort(-cm.diagonal())\n",
    "\n",
    "\n",
    "cm_norm = confusion_matrix(\n",
    "    df[\"normalized_label\"],\n",
    "    df[\"normalized_pred\"],\n",
    "    labels=labels,\n",
    "    normalize=\"true\",\n",
    ")\n",
    "cm_sorted = cm_norm[order, :][:, order]\n",
    "\n",
    "labels_sorted = labels[order]\n",
    "\n",
    "sns.heatmap(\n",
    "    cm_sorted,\n",
    "    vmin=0.0,\n",
    "    vmax=1.0,\n",
    "    cmap=\"Blues\",\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cbar=False,\n",
    "    xticklabels=labels_sorted,\n",
    "    yticklabels=labels_sorted,\n",
    ")\n",
    "\n",
    "plt.title(\"Confusion Matrix\", fontdict={\"fontsize\": 20})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
