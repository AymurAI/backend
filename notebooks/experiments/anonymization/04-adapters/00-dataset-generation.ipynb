{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"/workspace/resources/data/restricted/anonymization/data-splits-2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\n",
    "    f\"{DATASET_PATH}/train-ready.txt\",\n",
    "    sep=\" \",\n",
    "    names=[\"token\", \"label\"],\n",
    "    skip_blank_lines=False,\n",
    ")\n",
    "\n",
    "val = pd.read_csv(\n",
    "    f\"{DATASET_PATH}/dev-ready.txt\",\n",
    "    sep=\" \",\n",
    "    names=[\"token\", \"label\"],\n",
    "    skip_blank_lines=False,\n",
    ")\n",
    "\n",
    "test = pd.read_csv(\n",
    "    f\"{DATASET_PATH}/test-ready.txt\",\n",
    "    sep=\" \",\n",
    "    names=[\"token\", \"label\"],\n",
    "    skip_blank_lines=False,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"train:\", len(train))\n",
    "print(\"val:\", len(val))\n",
    "print(\"test:\", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from more_itertools import collapse, unique_everseen\n",
    "\n",
    "labels = set(train[\"label\"]) - {np.nan, \"O\"}\n",
    "labels = sorted(labels)\n",
    "labels = (re.sub(\"[BI]-\", \"\", label) for label in labels)\n",
    "labels = ((f\"B-{label}\", f\"I-{label}\") for label in labels)\n",
    "labels = collapse(labels)\n",
    "labels = unique_everseen(labels)\n",
    "labels = [\"O\"] + list(labels)\n",
    "print(labels)\n",
    "\n",
    "code2label = {code: label for code, label in enumerate(labels)}\n",
    "label2code = {label: code for code, label in code2label.items()}\n",
    "\n",
    "print(\"nlabels:\", len(labels))\n",
    "print(\"nlabels:\", len(code2label))\n",
    "print(\"nlabels:\", len(label2code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aymurai.datasets.utils import pandas_to_dataset\n",
    "from datasets import DatasetDict\n",
    "\n",
    "\n",
    "dataset = DatasetDict(\n",
    "    {\n",
    "        \"train\": pandas_to_dataset(train, label2code),\n",
    "        \"validation\": pandas_to_dataset(val, label2code),\n",
    "        \"test\": pandas_to_dataset(test, label2code),\n",
    "    }\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import hash\n",
    "\n",
    "df_train = dataset[\"train\"].to_pandas()\n",
    "df_dev = dataset[\"validation\"].to_pandas()\n",
    "df_test = dataset[\"test\"].to_pandas()\n",
    "\n",
    "# apply hash to fast compare dupplicated\n",
    "df_train[\"hash\"] = df_train[\"tokens\"].str.join(\" \").apply(hash)\n",
    "df_dev[\"hash\"] = df_dev[\"tokens\"].str.join(\" \").apply(hash)\n",
    "df_test[\"hash\"] = df_test[\"tokens\"].str.join(\" \").apply(hash)\n",
    "\n",
    "# drop duplicates\n",
    "df_train.drop_duplicates(subset=\"hash\", inplace=True)\n",
    "df_dev.drop_duplicates(subset=\"hash\", inplace=True)\n",
    "df_test.drop_duplicates(subset=\"hash\", inplace=True)\n",
    "\n",
    "# get train hashes\n",
    "train_hash = set(df_train[\"hash\"])\n",
    "dev_hash = set(df_dev[\"hash\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aymurai.utils.display.pandas import pandas_context\n",
    "\n",
    "options = {}\n",
    "options[\"display.max_colwidth\"] = 0\n",
    "\n",
    "with pandas_context(**options):\n",
    "    aux = df_train.query(\"hash in @train_hash and hash in @dev_hash\")\n",
    "    aux[\"ntags\"] = aux[\"tags\"].apply(lambda x: np.sum(x))\n",
    "    display(aux.query(\"ntags > 0\"))\n",
    "    # display(aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop paragraphs shared between datasets\n",
    "# df_dev.query(\"hash not in @train_hash\", inplace=True)\n",
    "# df_test.query(\"hash not in @train_hash and hash not in @dev_hash\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"] = Dataset.from_pandas(df_train)\n",
    "dataset[\"validation\"] = Dataset.from_pandas(df_dev)\n",
    "dataset[\"test\"] = Dataset.from_pandas(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(dataset[\"train\"][\"hash\"]).intersection(set(dataset[\"validation\"][\"hash\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import srsly\n",
    "\n",
    "DATASET_NAME = (\n",
    "    \"/resources/data/restricted/anonymization/annonimization-dataset-pruned-2023-09-06\"\n",
    ")\n",
    "\n",
    "dataset.save_to_disk(DATASET_NAME)\n",
    "with open(f\"{DATASET_NAME}/label_mapping.json\", \"w\") as file:\n",
    "    json = srsly.json_dumps(label2code)\n",
    "    file.write(json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
