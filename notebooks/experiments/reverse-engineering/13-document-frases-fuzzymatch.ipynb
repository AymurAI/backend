{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport aymurai.pattern.fuzzymatch\n",
    "%aimport aymurai.pattern.fuzzytagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "import locale \n",
    "\n",
    "locale.setlocale(locale.LC_ALL, 'es_AR.UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/resources/data/preprocessed.csv')\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_cats = [\n",
    "    \"violencia_de_genero\",\n",
    "    \"v_fisica\",\n",
    "    \"v_psic\",\n",
    "    \"v_econ\",\n",
    "    \"v_sex\",\n",
    "    \"v_soc\",\n",
    "    \"v_amb\",\n",
    "    \"v_simb\",\n",
    "    \"v_polit\",\n",
    "]\n",
    "bool_violence_cats = [f\"have:{cat}\" for cat in violence_cats]\n",
    "for cat in violence_cats:\n",
    "    data[f\"have:{cat}\"] = data[cat].apply(lambda v: v == \"si\")\n",
    "\n",
    "data[\"have:violence\"] = data[bool_violence_cats].sum(axis=1)\n",
    "\n",
    "frases_categories = ['no_corresponde', 'no corresponde', 'sin frases', 's/d']\n",
    "data['have:frase'] = data['frases_agresion'].apply(lambda s: s not in frases_categories)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract full text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import textract\n",
    "from zipfile import BadZipFile\n",
    "import unicodedata\n",
    "\n",
    "def get_fulltext(path: str) -> str:\n",
    "    if not isinstance(path, str) or not os.path.exists(path):\n",
    "        return \"missing\"\n",
    "    try:\n",
    "        docu = textract.process(path, extension='odt').decode('utf-8')\n",
    "        docu = unicodedata.normalize('NFKD', docu)\n",
    "        return docu\n",
    "    except (BadZipFile, KeyError):\n",
    "        return \"corrupted\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "parallel = Parallel(n_jobs=10)\n",
    "get_fulltext_ = delayed(get_fulltext)\n",
    "data['fulltext'] = parallel(get_fulltext_(path) for path in tqdm(data['path']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mark corrupt or missing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['valid_file'] = ~np.logical_or(data['fulltext'] == 'corrupted', data['fulltext'] == 'missing')\n",
    "data['valid_file'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filterout invalid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.query('valid_file', inplace=True)\n",
    "predict = data.copy()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register = data.loc[696]\n",
    "register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aymurai.pattern.fuzzytagging import FuzzyEntityTagger, FuzzyDateEntityTagger\n",
    "\n",
    "es = spacy.blank('es')\n",
    "nlp = spacy.load('es_dep_news_trf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = register['frases_agresion']\n",
    "# text = text_normalize(text)\n",
    "quotes = nlp(text)\n",
    "\n",
    "print(list(quotes.sents))\n",
    "displacy.render(quotes, 'dep', options={'collapse_punct': False, 'compact': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = FuzzyEntityTagger()\n",
    "tagger.add('agression_quote', [str(quote) for quote in quotes.sents])\n",
    "tagger.add('n_expte_eje', [register['n_expte_eje'].replace('_', '/')])\n",
    "tagger.add('firma', [register['firma'].replace('_', '/'), 'Pablo C. Casas'])\n",
    "tagger.add('materia', ['contravencional'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_tagger = FuzzyDateEntityTagger()\n",
    "date_tagger.add('fecha_resolucion', [r'%-d de %B de %Y', r'%d de %B de %Y'], reference=pd.to_datetime(register['date']), dd_max=pd.Timedelta(5, unit='D'))\n",
    "date_tagger.add('hora_de_inicio', [r'%H[\\.:]%M horas'], reference=pd.Timestamp(f\"1900/01/01 {register['hora_de_inicio']}\"), dd_max=pd.Timedelta(5, unit='m'))\n",
    "date_tagger.add('hora_de_cierre', [r'%H[\\.:]%M horas'], reference=pd.Timestamp(f\"1900/01/01 {register['hora_de_cierre']}\"), dd_max=pd.Timedelta(5, unit='m'))\n",
    "# date_tagger.add('hora_inicio', [r'%H[\\.:]%M horas'])\n",
    "# date_tagger.add('date', [r'%d de %B de %Y'], pd.Timestamp('11/03/2017'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = es(register['fulltext'])\n",
    "doc = tagger(doc)\n",
    "doc = date_tagger(doc)\n",
    "displacy.render(doc, 'ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.query('n_expte_eje == \"20751_2017\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data.loc[2141]\n",
    "doc = es(a['fulltext'])\n",
    "doc = tagger(doc)\n",
    "doc = date_tagger(doc)\n",
    "displacy.render(doc, 'ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
