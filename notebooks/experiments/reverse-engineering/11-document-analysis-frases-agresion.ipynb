{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from detoxify import Detoxify\n",
    "\n",
    "import locale \n",
    "\n",
    "locale.setlocale(locale.LC_ALL, 'es_AR.UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/resources/data/preprocessed.csv')\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_cats = [\n",
    "    \"violencia_de_genero\",\n",
    "    \"v_fisica\",\n",
    "    \"v_psic\",\n",
    "    \"v_econ\",\n",
    "    \"v_sex\",\n",
    "    \"v_soc\",\n",
    "    \"v_amb\",\n",
    "    \"v_simb\",\n",
    "    \"v_polit\",\n",
    "]\n",
    "bool_violence_cats = [f\"have:{cat}\" for cat in violence_cats]\n",
    "for cat in violence_cats:\n",
    "    data[f\"have:{cat}\"] = data[cat].apply(lambda v: v == \"si\")\n",
    "\n",
    "data[\"have:violence\"] = data[bool_violence_cats].sum(axis=1)\n",
    "\n",
    "frases_categories = ['no_corresponde', 'no corresponde', 'sin frases', 's/d']\n",
    "data['have:frase'] = data['frases_agresion'].apply(lambda s: s not in frases_categories)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract full text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import textract\n",
    "from zipfile import BadZipFile\n",
    "import unicodedata\n",
    "\n",
    "def get_fulltext(path: str) -> str:\n",
    "    if not isinstance(path, str) or not os.path.exists(path):\n",
    "        return \"missing\"\n",
    "    try:\n",
    "        docu = textract.process(path, extension='odt').decode('utf-8')\n",
    "        docu = unicodedata.normalize('NFKD', docu)\n",
    "        return docu\n",
    "    except (BadZipFile, KeyError):\n",
    "        return \"corrupted\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "parallel = Parallel(n_jobs=10)\n",
    "get_fulltext_ = delayed(get_fulltext)\n",
    "data['fulltext'] = parallel(get_fulltext_(path) for path in tqdm(data['path']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mark corrupt or missing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['valid_file'] = ~np.logical_or(data['fulltext'] == 'corrupted', data['fulltext'] == 'missing')\n",
    "data['valid_file'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filterout invalid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.query('valid_file', inplace=True)\n",
    "predict = data.copy()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# categorice documents with toxicity metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detoxify = Detoxify('multilingual', device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = ['estupido', 'te amo', 'sos un pelotudo', 'eres una pelotuda', \"hijo de puta\", 'que boludo', 'jajaja me mata lo boludo que sos, es re gracioso']\n",
    "# results = Detoxify(\"multilingual\", device='cpu').predict(input_text)\n",
    "results = detoxify.predict(input_text)\n",
    "pd.DataFrame(results, index=input_text)\n",
    "pd.DataFrame(results).to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from tqdm.auto import tqdm\n",
    "from more_itertools import chunked\n",
    "import re\n",
    "\n",
    "def doc_max_toxicity(text: str):\n",
    "    utterances = re.split(r'\\n|\\.', text)\n",
    "    utterances = filter(len, utterances)\n",
    "    chunks = chunked(utterances, 10)\n",
    "    results = pd.concat([pd.DataFrame(detoxify.predict(chunk)) for chunk in chunks])\n",
    "\n",
    "    return results.describe().to_dict()\n",
    "\n",
    "toxicity = [doc_max_toxicity(doc) for doc in tqdm(data['fulltext'])]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "idx = 5\n",
    "mask = data['have:frase']\n",
    "print(data.loc[mask, 'frases_agresion'].iloc[idx])\n",
    "print(80*'=')\n",
    "re.split(r'\\n', data.loc[mask, 'fulltext'].iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detoxify.predict(['Fiscal: la presente causa se inicia con la denuncia el 18 de octubre del corriente en la Comisaría 45, de la señora L. M. R. R., quien manifiesta que el día anterior tomó conocimiento por parte de su hija E. A. S., de 17 años de edad, que dicho día se encontraba sola en el interior de un aula de la Escuela Técnica No, sita en de esta ciudad, finalizando un examen, y que su profesor de taller de nombre G. le preguntó “¿Ya tuviste relaciones sexuales?”, “¿Tenes novio?”, “¿Te parezco fachero?”; para luego referirle que le quería enseñar algo, tomar su mano y apoyarla sobre su pantalón, más precisamente sobre sus genitales, en momentos en que estaría teniendo una erección, tras lo cual la menor salió corriendo del aula.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_ = {doc: toxi for doc, toxi in zip(data['path'], toxicity)}\n",
    "json_\n",
    "\n",
    "with open('detoxify-docs-out.json', 'w') as file:\n",
    "    json.dump(json_, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('detoxify-docs-out.json', 'r') as file:\n",
    "    json_ = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analyse toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stat(path: str, stat: str = 'max'):\n",
    "    df = pd.DataFrame(json_.get(path, []))\n",
    "    if df.empty:\n",
    "        return\n",
    "    scores = df.loc[stat, :]\n",
    "    scores['path'] = path\n",
    "    return pd.DataFrame(scores).T\n",
    "\n",
    "max_doc_scores = [get_stat(path) for path in tqdm(json_.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxicity = pd.concat(max_doc_scores, ignore_index=True)\n",
    "toxicity = pd.merge(toxicity, data, on='path')\n",
    "toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = ['no corresponde', 'no_corresponde', 'sin frases' 's/d']\n",
    "toxicity['have:frase'] = toxicity['frases_agresion'].apply(lambda s: s not in aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "pio.renderers.default = \"notebook\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_categories = ['toxicity', 'severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat', 'sexual_explicit']\n",
    "toxicity_mean = toxicity[toxic_categories].mean(axis=1)\n",
    "toxicity_max = toxicity[toxic_categories].max(axis=1)\n",
    "px.violin(toxicity, x='have:frase', y=toxicity_max, box=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter_matrix(toxicity, dimensions=toxic_categories, color='have:frase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "import plotly.express as px\n",
    "\n",
    "features = toxicity[toxic_categories]\n",
    "\n",
    "umap_2d = UMAP(n_components=2, init='random', random_state=0)\n",
    "umap_3d = UMAP(n_components=3, init='random', random_state=0)\n",
    "\n",
    "proj_2d = umap_2d.fit_transform(features)\n",
    "proj_3d = umap_3d.fit_transform(features)\n",
    "\n",
    "fig_2d = px.scatter(\n",
    "    proj_2d, x=0, y=1,\n",
    "    color=toxicity['have:frase'], labels={'color': 'have:frase'}\n",
    ")\n",
    "fig_3d = px.scatter_3d(\n",
    "    proj_3d, x=0, y=1, z=2,\n",
    "    color=toxicity['have:frase'], labels={'color': 'have:frase'}\n",
    ")\n",
    "fig_3d.update_traces(marker_size=5)\n",
    "\n",
    "fig_2d.show()\n",
    "fig_3d.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
