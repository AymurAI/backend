{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "database = pd.read_csv('/resources/data/dump-20221027/set_de_datos_con_perspectiva_de_genero-database.csv')\n",
    "validation_fields = pd.read_csv('/resources/data/dump-20221027/set_de_datos_con_perspectiva_de_genero-listado_validacion.csv')\n",
    "validation_codes = pd.read_csv('/resources/data/dump-20221027/validacion-codigos.csv')\n",
    "database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "def strip_accents_spain(string, accents=('COMBINING ACUTE ACCENT', 'COMBINING GRAVE ACCENT')):\n",
    "    accents = set(map(unicodedata.lookup, accents))\n",
    "    chars = [c for c in unicodedata.normalize('NFD', string) if c not in accents]\n",
    "    return unicodedata.normalize('NFC', ''.join(chars))\n",
    "\n",
    "def normalize(text: str) -> str:\n",
    "    text = strip_accents_spain(text)\n",
    "    text = re.sub(r\"[_\\s]+\", \" \", text)\n",
    "    text = text.strip()\n",
    "    text = re.sub(r\" \", \"_\", text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "\n",
    "def is_in_public_base(text: str, column: str) -> bool:\n",
    "    return text in set(database[column])\n",
    "\n",
    "\n",
    "def is_in_validation_codes(text: str, column: str) -> bool:\n",
    "    return text in set(validation_codes[column])\n",
    "\n",
    "\n",
    "def is_in_validation_fields(text: str, column: str) -> bool:\n",
    "    return text in set(validation_fields[column])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conducta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "values = pd.concat([validation_codes['CONDUCTA'], database['CONDUCTA']], ignore_index=True)\n",
    "values = values.dropna()\n",
    "values = values.drop_duplicates()\n",
    "values = values.sort_values()\n",
    "\n",
    "en_base = values.apply(lambda x: is_in_public_base(x, 'CONDUCTA'))\n",
    "en_val = values.apply(lambda x: is_in_validation_codes(x, 'CONDUCTA'))\n",
    "\n",
    "norm = values.apply(normalize)\n",
    "norm\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'CAMPO': 'CONDUCTA',\n",
    "        'ORIGINAL': values,\n",
    "        'EN_BASE_PUBLICA': en_base,\n",
    "        'EN_LISTA_VALIDACION': en_val,\n",
    "        'REQUIERE_NORMALIZACION': norm != values,\n",
    "        'NORMALIZADO': norm,\n",
    "    }\n",
    "\n",
    ")\n",
    "\n",
    "mapper = pd.concat([mapper, df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conducta Descripcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "values = pd.concat([validation_codes['CONDUCTA_DESCRIPCION'], database['CONDUCTA_DESCRIPCION']], ignore_index=True)\n",
    "values = values.dropna()\n",
    "values = values.drop_duplicates()\n",
    "values = values.sort_values()\n",
    "\n",
    "en_base = values.apply(lambda x: is_in_public_base(x, 'CONDUCTA_DESCRIPCION'))\n",
    "en_val = values.apply(lambda x: is_in_validation_codes(x, 'CONDUCTA_DESCRIPCION'))\n",
    "\n",
    "norm = values.apply(normalize)\n",
    "norm\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'CAMPO': 'CONDUCTA_DESCRIPCION',\n",
    "        'ORIGINAL': values,\n",
    "        'EN_BASE_PUBLICA': en_base,\n",
    "        'EN_LISTA_VALIDACION': en_val,\n",
    "        'REQUIERE_NORMALIZACION': norm != values,\n",
    "        'NORMALIZADO': norm,\n",
    "    }\n",
    "\n",
    ")\n",
    "\n",
    "mapper = pd.concat([mapper, df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PERSONA_ACUSADA_NO_DETERMINADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "values = pd.concat([validation_fields['PERSONA_ACUSADA_NO_DETERMINADA'], database['PERSONA_ACUSADA_NO_DETERMINADA']], ignore_index=True)\n",
    "values = values.dropna()\n",
    "values = values.drop_duplicates()\n",
    "values = values.sort_values()\n",
    "\n",
    "norm = values.apply(normalize)\n",
    "norm\n",
    "\n",
    "en_base = values.apply(lambda x: is_in_public_base(x, 'PERSONA_ACUSADA_NO_DETERMINADA'))\n",
    "en_val = values.apply(lambda x: is_in_validation_fields(x, 'PERSONA_ACUSADA_NO_DETERMINADA'))\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'CAMPO': 'PERSONA_ACUSADA_NO_DETERMINADA',\n",
    "        'ORIGINAL': values,\n",
    "        'EN_BASE_PUBLICA': en_base,\n",
    "        'EN_LISTA_VALIDACION': en_val,\n",
    "        'REQUIERE_NORMALIZACION': norm != values,\n",
    "        'NORMALIZADO': norm\n",
    "    }\n",
    ")\n",
    "\n",
    "# df\n",
    "mapper = pd.concat([mapper, df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODALIDAD_DE_LA_VIOLENCIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "values = pd.concat([validation_fields['MODALIDAD_DE_LA_VIOLENCIA'], database['MODALIDAD_DE_LA_VIOLENCIA']], ignore_index=True)\n",
    "values = values.dropna()\n",
    "values = values.drop_duplicates()\n",
    "values = values.sort_values()\n",
    "\n",
    "norm = values.apply(normalize)\n",
    "norm\n",
    "\n",
    "en_base = values.apply(lambda x: is_in_public_base(x, 'MODALIDAD_DE_LA_VIOLENCIA'))\n",
    "en_val = values.apply(lambda x: is_in_validation_fields(x, 'MODALIDAD_DE_LA_VIOLENCIA'))\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'CAMPO': 'MODALIDAD_DE_LA_VIOLENCIA',\n",
    "        'ORIGINAL': values,\n",
    "        'EN_BASE_PUBLICA': en_base,\n",
    "        'EN_LISTA_VALIDACION': en_val,\n",
    "        'REQUIERE_NORMALIZACION': norm != values,\n",
    "        'NORMALIZADO': norm\n",
    "    }\n",
    ")\n",
    "\n",
    "# df\n",
    "mapper = pd.concat([mapper, df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIVEL_INSTRUCCION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = pd.concat(\n",
    "    [\n",
    "        validation_fields[\"NIVEL_INSTRUCCION\"],\n",
    "        database[\"NIVEL_INSTRUCCION_ACUSADO/A\"],\n",
    "        database[\"NIVEL_INSTRUCCION_DENUNCIANTE\"],\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "values = values.dropna()\n",
    "values = values.drop_duplicates()\n",
    "values = values.sort_values()\n",
    "\n",
    "norm = values.apply(normalize)\n",
    "norm\n",
    "\n",
    "en_base = values.apply(\n",
    "    lambda x: x\n",
    "    in set(\n",
    "        pd.concat(\n",
    "            [\n",
    "                database[\"NIVEL_INSTRUCCION_DENUNCIANTE\"],\n",
    "                database[\"NIVEL_INSTRUCCION_ACUSADO/A\"],\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "en_val = values.apply(lambda x: is_in_validation_fields(x, \"NIVEL_INSTRUCCION\"))\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"CAMPO\": \"NIVEL_INSTRUCCION\",\n",
    "        \"ORIGINAL\": values,\n",
    "        \"EN_BASE_PUBLICA\": en_base,\n",
    "        \"EN_LISTA_VALIDACION\": en_val,\n",
    "        \"REQUIERE_NORMALIZACION\": norm != values,\n",
    "        \"NORMALIZADO\": norm,\n",
    "    }\n",
    ")\n",
    "\n",
    "# df\n",
    "mapper = pd.concat([mapper, df])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = pd.concat(\n",
    "    [\n",
    "        validation_fields[\"GENERO\"],\n",
    "        database[\"GENERO_ACUSADO/A\"],\n",
    "        database[\"GENERO_DENUNCIANTE\"],\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "values = values.dropna()\n",
    "values = values.drop_duplicates()\n",
    "values = values.sort_values()\n",
    "\n",
    "norm = values.apply(normalize)\n",
    "norm\n",
    "\n",
    "en_base = values.apply(\n",
    "    lambda x: x\n",
    "    in set(\n",
    "        pd.concat(\n",
    "            [\n",
    "                database[\"GENERO_DENUNCIANTE\"],\n",
    "                database[\"GENERO_ACUSADO/A\"],\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "en_val = values.apply(lambda x: is_in_validation_fields(x, \"GENERO\"))\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"CAMPO\": \"GENERO\",\n",
    "        \"ORIGINAL\": values,\n",
    "        \"EN_BASE_PUBLICA\": en_base,\n",
    "        \"EN_LISTA_VALIDACION\": en_val,\n",
    "        \"REQUIERE_NORMALIZACION\": norm != values,\n",
    "        \"NORMALIZADO\": norm,\n",
    "    }\n",
    ")\n",
    "\n",
    "# df\n",
    "mapper = pd.concat([mapper, df])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FRECUENCIA_EPISODIOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "values = pd.concat([validation_fields['FRECUENCIA_EPISODIOS'], database['FRECUENCIA_EPISODIOS']], ignore_index=True)\n",
    "values = values.dropna()\n",
    "values = values.drop_duplicates()\n",
    "values = values.sort_values()\n",
    "\n",
    "norm = values.apply(normalize)\n",
    "norm\n",
    "\n",
    "en_base = values.apply(lambda x: is_in_public_base(x, 'FRECUENCIA_EPISODIOS'))\n",
    "en_val = values.apply(lambda x: is_in_validation_fields(x, 'FRECUENCIA_EPISODIOS'))\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'CAMPO': 'FRECUENCIA_EPISODIOS',\n",
    "        'ORIGINAL': values,\n",
    "        'EN_BASE_PUBLICA': en_base,\n",
    "        'EN_LISTA_VALIDACION': en_val,\n",
    "        'REQUIERE_NORMALIZACION': norm != values,\n",
    "        'NORMALIZADO': norm\n",
    "    }\n",
    ")\n",
    "\n",
    "# df\n",
    "mapper = pd.concat([mapper, df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RELACION_Y_TIPO_ENTRE_ACUSADO/A_Y_DENUNCIANTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "values = pd.concat([validation_fields['RELACION_Y_TIPO_ENTRE_ACUSADO/A_Y_DENUNCIANTE'], database['RELACION_Y_TIPO_ENTRE_ACUSADO/A_Y_DENUNCIANTE']], ignore_index=True)\n",
    "values = values.dropna()\n",
    "values = values.drop_duplicates()\n",
    "values = values.sort_values()\n",
    "\n",
    "norm = values.apply(normalize)\n",
    "norm\n",
    "\n",
    "en_base = values.apply(lambda x: is_in_public_base(x, 'RELACION_Y_TIPO_ENTRE_ACUSADO/A_Y_DENUNCIANTE'))\n",
    "en_val = values.apply(lambda x: is_in_validation_fields(x, 'RELACION_Y_TIPO_ENTRE_ACUSADO/A_Y_DENUNCIANTE'))\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'CAMPO': 'RELACION_Y_TIPO_ENTRE_ACUSADO/A_Y_DENUNCIANTE',\n",
    "        'ORIGINAL': values,\n",
    "        'EN_BASE_PUBLICA': en_base,\n",
    "        'EN_LISTA_VALIDACION': en_val,\n",
    "        'REQUIERE_NORMALIZACION': norm != values,\n",
    "        'NORMALIZADO': norm\n",
    "    }\n",
    ")\n",
    "\n",
    "# df\n",
    "mapper = pd.concat([mapper, df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZONA_DEL_HECHO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "values = pd.concat([validation_fields['LUGAR DEL HECHO'], database['ZONA_DEL_HECHO']], ignore_index=True)\n",
    "values = values.dropna()\n",
    "values = values.drop_duplicates()\n",
    "values = values.sort_values()\n",
    "\n",
    "en_base = values.apply(lambda x: is_in_public_base(x, 'ZONA_DEL_HECHO'))\n",
    "en_val = values.apply(lambda x: is_in_validation_fields(x, 'LUGAR DEL HECHO'))\n",
    "\n",
    "norm = values.apply(normalize)\n",
    "norm\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'CAMPO': 'ZONA_DEL_HECHO',\n",
    "        'ORIGINAL': values,\n",
    "        'EN_BASE_PUBLICA': en_base,\n",
    "        'EN_LISTA_VALIDACION': en_val,\n",
    "        'REQUIERE_NORMALIZACION': norm != values,\n",
    "        'NORMALIZADO': norm,\n",
    "    }\n",
    "\n",
    ")\n",
    "\n",
    "mapper = pd.concat([mapper, df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LUGAR DEL HECHO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "values = pd.concat([validation_fields['VIA_PUBLICA_O_DENTRO_DE_DOMICILIO'], database['LUGAR_DEL_HECHO\\n']], ignore_index=True)\n",
    "values = values.dropna()\n",
    "values = values.drop_duplicates()\n",
    "values = values.sort_values()\n",
    "\n",
    "en_base = values.apply(lambda x: is_in_public_base(x, 'LUGAR_DEL_HECHO\\n'))\n",
    "en_val = values.apply(lambda x: is_in_validation_fields(x, 'VIA_PUBLICA_O_DENTRO_DE_DOMICILIO'))\n",
    "\n",
    "norm = values.apply(normalize)\n",
    "norm\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'CAMPO': 'LUGAR_DEL_HECHO',\n",
    "        'ORIGINAL': values,\n",
    "        'EN_BASE_PUBLICA': en_base,\n",
    "        'EN_LISTA_VALIDACION': en_val,\n",
    "        'REQUIERE_NORMALIZACION': norm != values,\n",
    "        'NORMALIZADO': norm,\n",
    "    }\n",
    "\n",
    ")\n",
    "\n",
    "mapper = pd.concat([mapper, df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OBJETO_DE_LA_RESOLUCION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "values = pd.concat([validation_fields['OBJETO_DE_LA_RESOLUCION'], database['OBJETO_DE_LA_RESOLUCION']], ignore_index=True)\n",
    "values = values.dropna()\n",
    "values = values.drop_duplicates()\n",
    "values = values.sort_values()\n",
    "\n",
    "norm = values.apply(normalize)\n",
    "norm\n",
    "\n",
    "en_base = values.apply(lambda x: is_in_public_base(x, 'OBJETO_DE_LA_RESOLUCION'))\n",
    "en_val = values.apply(lambda x: is_in_validation_fields(x, 'OBJETO_DE_LA_RESOLUCION'))\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'CAMPO': 'OBJETO_DE_LA_RESOLUCION',\n",
    "        'ORIGINAL': values,\n",
    "        'EN_BASE_PUBLICA': en_base,\n",
    "        'EN_LISTA_VALIDACION': en_val,\n",
    "        'REQUIERE_NORMALIZACION': norm != values,\n",
    "        'NORMALIZADO': norm\n",
    "    }\n",
    ")\n",
    "\n",
    "mapper = pd.concat([mapper, df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DETALLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "values = pd.concat([validation_fields['DETALLE'], database['DETALLE']], ignore_index=True)\n",
    "values = values.dropna()\n",
    "values = values.drop_duplicates()\n",
    "values = values.sort_values()\n",
    "\n",
    "norm = values.apply(normalize)\n",
    "norm\n",
    "\n",
    "en_base = values.apply(lambda x: is_in_public_base(x, 'DETALLE'))\n",
    "en_val = values.apply(lambda x: is_in_validation_fields(x, 'DETALLE'))\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'CAMPO': 'DETALLE',\n",
    "        'ORIGINAL': values,\n",
    "        'EN_BASE_PUBLICA': en_base,\n",
    "        'EN_LISTA_VALIDACION': en_val,\n",
    "        'REQUIERE_NORMALIZACION': norm != values,\n",
    "        'NORMALIZADO': norm\n",
    "    }\n",
    ")\n",
    "\n",
    "mapper = pd.concat([mapper, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = mapper.drop_duplicates()\n",
    "mapper.to_csv('mapeo-normalizacion-campos.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def labelstudio_choice(value: str) -> str:\n",
    "    value = value.strip()\n",
    "    return f'<Choice value=\"{value}\" />' \n",
    "\n",
    "def is_choice(value: str):\n",
    "    return value not in ['no_corresponde', 's/d']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from more_itertools import unique_everseen\n",
    "\n",
    "choices = mapper.query('CAMPO == \"LUGAR_DEL_HECHO\"')['NORMALIZADO']\n",
    "choices = filter(is_choice, choices)\n",
    "choices = unique_everseen(choices)\n",
    "choices = map(labelstudio_choice, choices)\n",
    "choices = list(choices)\n",
    "\n",
    "for choice in choices:\n",
    "    print(choice)\n",
    "# fields"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
