# codeblock generated by devtools
# source: /workspace/notebooks/dev/patterns/names/04-firma.ipynb


import re
from copy import deepcopy

import spacy

from aymurai.meta.types import DataItem, DataBlock
from aymurai.spacy.components.fuzzy import FuzzyMatcher
from aymurai.meta.pipeline_interfaces import TrainModule


class DummyExtractorAffiliation(TrainModule):
    def __init__(self):
        self.nlp = spacy.blank("es")
        self.matcher = FuzzyMatcher(self.nlp.vocab)
        self.matcher.add(
            "FIRMA", patterns=[self.nlp.make_doc(t) for t in ["juez", "jueza"]]
        )
        self.matcher.add(
            "IMPUTADO",
            patterns=[self.nlp.make_doc(t) for t in ["acusado", "imputado"]],
        )

    def save(self, path: str):
        return

    def load(self, path: str):
        return

    def fit(self, train: DataBlock, val: DataBlock):
        return

    def predict(self, data: DataBlock) -> DataBlock:
        data = [self.predict_single(item) for item in data]

        return data

    def get_ntokens(self, text: str, n: int = 1):
        tokens = self.nlp.make_doc(text)
        n = min(len(tokens), n)
        return tokens[:n].text if n else ""

    def predict_single(self, item: DataItem) -> DataItem:
        item = deepcopy(item)

        # format prediction
        if "predictions" not in item:
            item["predictions"] = {}
        if "records" not in item["predictions"]:
            item["predictions"]["records"] = {}
        if "entities" not in item["predictions"]:
            item["predictions"]["entities"] = []
        if "doc-cats" not in item["predictions"]:
            item["predictions"]["doc-cats"] = {}
        if "affiliations" not in item["predictions"]:
            item["predictions"]["affiliations"] = []
        item["predictions"]["doc-cats"]["firma"] = None
        item["predictions"]["records"]["firma"] = []

        ents = []
        if "entities" in item["data"]:
            ents += item["data"]["entities"]

        # if there is no entities just pass
        if not ents:
            return item

        #
        names = filter(lambda x: x["label"] == "PER", ents)
        names = sorted(names, key=lambda e: e["start"])

        if not names:
            return item

        for span in names:
            pre = span["context_pre"]
            pre = re.sub(r".*\n|\W", "", pre)
            pre = self.get_ntokens(pre, n=2)

            post = span["context_post"]
            post = re.sub(r"\n.*|\W", "", post)
            post = self.get_ntokens(post, n=2)

            matches = self.matcher(self.nlp.make_doc(f"{pre} {post}"))
            matches = sorted(matches, key=lambda x: x[3])
            if not matches:
                continue

            candidate = matches[0]
            span["label"] = candidate[0]

            # replace entity if it is FIRMA (JUEZ)
            if candidate[0] == "FIRMA":
                item["predictions"]["entities"].append(span)
                item["predictions"]["records"]["firma"].append(span["text"])
                item["predictions"]["doc-cats"]["firma"] = span["text"]

            item["predictions"]["affiliations"].append(span)

        return item
